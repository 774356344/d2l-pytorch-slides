{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Recurrent Neural Network Implementation from Scratch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    },
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "\n",
    "class RNNScratch(d2l.Module):  \n",
    "    def __init__(self, num_inputs, num_hiddens, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.W_xh = nn.Parameter(\n",
    "            torch.randn(num_inputs, num_hiddens) * sigma)\n",
    "        self.W_hh = nn.Parameter(\n",
    "            torch.rand(num_hiddens, num_hiddens) * sigma)\n",
    "        self.b_h = nn.Parameter(torch.zeros(num_hiddens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following `forward` method defines how to compute the output and hidden state at a time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "@d2l.add_to_class(RNNScratch)  \n",
    "def forward(self, inputs, state=None):\n",
    "    if state is not None:\n",
    "        state, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        state = torch.tanh(torch.matmul(X, self.W_xh) + (\n",
    "            torch.matmul(state, self.W_hh) if state is not None else 0)\n",
    "                         + self.b_h)\n",
    "        outputs.append(state)\n",
    "    return outputs, state\n",
    "\n",
    "batch_size, num_inputs, num_hiddens, num_steps = 2, 16, 32, 100\n",
    "rnn = RNNScratch(num_inputs, num_hiddens)\n",
    "X = torch.ones((num_steps, batch_size, num_inputs))\n",
    "outputs, state = rnn(X)\n",
    "\n",
    "def check_len(a, n):  \n",
    "    assert len(a) == n, f'list\\'s len {len(a)} != expected length {n}'\n",
    "\n",
    "def check_shape(a, shape):  \n",
    "    assert a.shape == shape, \\\n",
    "            f'tensor\\'s shape {a.shape} != expected shape {shape}'\n",
    "\n",
    "d2l.check_len(outputs, num_steps)\n",
    "d2l.check_shape(outputs[0], (batch_size, num_hiddens))\n",
    "d2l.check_shape(state, (batch_size, num_hiddens))\n",
    "\n",
    "class RNNLMScratch(d2l.Classification):  \n",
    "    def __init__(self, rnn, vocab_size, lr=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        self.W_hq = nn.Parameter(\n",
    "            torch.randn(\n",
    "                self.rnn.num_hiddens, self.vocab_size) * self.rnn.sigma)\n",
    "        self.b_q = nn.Parameter(torch.zeros(self.vocab_size))\n",
    "    def training_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        self.plot('ppl', torch.exp(l), train=True)\n",
    "        return l\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        self.plot('ppl', torch.exp(l), train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "11"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "F.one_hot(torch.tensor([0, 2]), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The shape of the minibatch\n",
    "is (batch size, number of time steps).\n",
    "The `one_hot` method transforms such a minibatch into a three-dimensional tensor with the last dimension equals to the vocabulary size (`len(vocab)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "@d2l.add_to_class(RNNLMScratch)  \n",
    "def one_hot(self, X):\n",
    "    return F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
    "\n",
    "@d2l.add_to_class(RNNLMScratch)  \n",
    "def output_layer(self, rnn_outputs):\n",
    "    outputs = [torch.matmul(H, self.W_hq) + self.b_q for H in rnn_outputs]\n",
    "    return torch.stack(outputs, 1)\n",
    "\n",
    "@d2l.add_to_class(RNNLMScratch)  \n",
    "def forward(self, X, state=None):\n",
    "    embs = self.one_hot(X)\n",
    "    rnn_outputs, _ = self.rnn(embs, state)\n",
    "    return self.output_layer(rnn_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check whether the forward computation outputs have the correct shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "model = RNNLMScratch(rnn, num_inputs)\n",
    "outputs = model(torch.ones((batch_size, num_steps), dtype=torch.int64))\n",
    "d2l.check_shape(outputs, (batch_size, num_steps, num_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gradient Clipping\n",
    "$$\\mathbf{g} \\leftarrow \\min\\left(1, \\frac{\\theta}{\\|\\mathbf{g}\\|}\\right) \\mathbf{g}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "17"
    },
    "origin_pos": 27,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "@d2l.add_to_class(d2l.Trainer)  \n",
    "def clip_gradients(self, grad_clip_val, model):\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > grad_clip_val:\n",
    "        for param in params:\n",
    "            param.grad[:] *= grad_clip_val / norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define a function to train the model in one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "26"
    },
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "data = d2l.TimeMachine(batch_size=1024, num_steps=32)\n",
    "rnn = RNNScratch(num_inputs=len(data.vocab), num_hiddens=32)\n",
    "model = RNNLMScratch(rnn, vocab_size=len(data.vocab), lr=1)\n",
    "trainer = d2l.Trainer(max_epochs=100, gradient_clip_val=1, num_gpus=1)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First define the prediction function\n",
    "to generate new characters following\n",
    "the user-provided `prefix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 33,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "@d2l.add_to_class(RNNLMScratch)  \n",
    "def predict(self, prefix, num_preds, vocab, device=None):\n",
    "    state, outputs = None, [vocab[prefix[0]]]\n",
    "    for i in range(len(prefix) + num_preds - 1):\n",
    "        X = torch.tensor([[outputs[-1]]], device=device)\n",
    "        embs = self.one_hot(X)\n",
    "        rnn_outputs, state = self.rnn(embs, state)\n",
    "        if i < len(prefix) - 1:\n",
    "            outputs.append(vocab[prefix[i + 1]])\n",
    "        else:\n",
    "            Y = self.output_layer(rnn_outputs)\n",
    "            outputs.append(int(Y.argmax(axis=2).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])\n",
    "\n",
    "model.predict('it has', 20, data.vocab, d2l.try_gpu())"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "language_info": {
   "name": "python"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}