{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Gated Recurrent Units (GRU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    },
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Initializing Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class GRUScratch(d2l.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        init_weight = lambda *shape: nn.Parameter(torch.randn(*shape) * sigma)\n",
    "        triple = lambda: (init_weight(num_inputs, num_hiddens),\n",
    "                          init_weight(num_hiddens, num_hiddens),\n",
    "                          nn.Parameter(torch.zeros(num_hiddens)))\n",
    "        self.W_xz, self.W_hz, self.b_z = triple()\n",
    "        self.W_xr, self.W_hr, self.b_r = triple()\n",
    "        self.W_xh, self.W_hh, self.b_h = triple()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The hidden state initialization function\n",
    "define the GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "@d2l.add_to_class(GRUScratch)\n",
    "def forward(self, inputs, H=None):\n",
    "    matmul_H = lambda A, B: torch.matmul(A, B) if H is not None else 0\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        Z = torch.sigmoid(torch.matmul(X, self.W_xz) + (\n",
    "            torch.matmul(H, self.W_hz) if H is not None else 0) + self.b_z)\n",
    "        if H is None: H = torch.zeros_like(Z)\n",
    "        R = torch.sigmoid(torch.matmul(X, self.W_xr) +\n",
    "                        torch.matmul(H, self.W_hr) + self.b_r)\n",
    "        H_tilda = torch.tanh(torch.matmul(X, self.W_xh) +\n",
    "                           torch.matmul(R * H, self.W_hh) + self.b_h)\n",
    "        H = Z * H + (1 - Z) * H_tilda\n",
    "        outputs.append(H)\n",
    "    return outputs, (H, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "data = d2l.TimeMachine(batch_size=1024, num_steps=32)\n",
    "gru = GRUScratch(num_inputs=len(data.vocab), num_hiddens=32)\n",
    "model = d2l.RNNLMScratch(gru, vocab_size=len(data.vocab), lr=4)\n",
    "trainer = d2l.Trainer(max_epochs=50, gradient_clip_val=1, num_gpus=1)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Concise Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class GRU(d2l.RNN):\n",
    "    def __init__(self, num_inputs, num_hiddens):\n",
    "        d2l.Module.__init__(self)\n",
    "        self.save_hyperparameters()\n",
    "        self.rnn = nn.GRU(num_inputs, num_hiddens)\n",
    "\n",
    "gru = GRU(num_inputs=len(data.vocab), num_hiddens=32)\n",
    "model = d2l.RNNLM(gru, vocab_size=len(data.vocab), lr=4)\n",
    "trainer.fit(model, data)\n",
    "\n",
    "model.predict('it has', 20, data.vocab, d2l.try_gpu())"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "language_info": {
   "name": "python"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}